{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BM25_FULL_DATA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Gr88kGU0W1ZB",
        "D_EUaa4Jg-HJ",
        "mgxBAVx3V8Z0",
        "dd6TmCc8XR4u",
        "KLtzbP8bi3m2"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrcbcFlITfnw",
        "outputId": "0efce1c3-602e-4541-a840-1b00389a609a"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0StEtH0rTwr1"
      },
      "source": [
        "# Document Ranking: BM25 -- Whole Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr88kGU0W1ZB"
      },
      "source": [
        "## Importing libraries and defining functions\n",
        "- Importing all necessary packages for the project (BM25, NLTK, spaCy, etc.)\n",
        "- Defining our personal helper functions necessary for projects\n",
        "- Loading our spaCy trained model for entity extraction and further pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YbUJpVFTnP8",
        "outputId": "9f3cfad5-c148-4cf6-fd74-81e0645c8098"
      },
      "source": [
        "!pip install rank-bm25"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rank-bm25) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SBny9BnTz9J",
        "outputId": "aaa5980a-e4b2-4dbf-cf85-5a716267820a"
      },
      "source": [
        "## import from BM25 package: https://github.com/dorianbrown/rank_bm25\n",
        "from rank_bm25 import BM25Plus, BM25Okapi, BM25L\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import ast\n",
        "import string\n",
        "import spacy\n",
        "\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "from nltk import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae2sv6m1ZNnH"
      },
      "source": [
        "## Loading model (nlp) to pre-process description column later --> DO ENTITY EXTRACTION\n",
        "nlp = spacy.load(\"/content/drive/Shareddrives/SI650 Project [Info Retrieval]/entity-model/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_EUaa4Jg-HJ"
      },
      "source": [
        "### Helper Functions\n",
        "- <b>process_text(df_col):</b> function to clean the description column (and title, in this notebook)\n",
        "- <b>standard_query(q):</b> function to standardize query for search (lemmatized, cleaned)\n",
        "- <b>query_scores(q):</b> function to get the scores for a given query (used in next helper function)\n",
        "- <b>top_n_queries(query, corpus, n):</b> return a full dataframe with data, based on the top query scores from previous function\n",
        "- <b>retrieve_docs (query):</b> return a df subset with our results\n",
        "- <b>evaluate_mAP (retrieved_docs, rel_column):</b> evaluate performance of retrieval using mean Average Precision @ 20 (Note: just for ground truth annotated data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_kqpZb_g9mq"
      },
      "source": [
        "def process_text(df_col):\n",
        "    \"\"\"\n",
        "    Helper function to help up process the description columns. Several NLP techniques implemented to get lemmatized, clean tokens\n",
        "    :input: dataframe column (description)\n",
        "    :output: list of stemmed, clean tokens\n",
        "    \"\"\"\n",
        "\n",
        "    ret_list = []\n",
        "\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "    stemmer = PorterStemmer()\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokenizer = RegexpTokenizer(pattern='\\w+|\\$[\\d\\.]+|\\S+')\n",
        "\n",
        "    to_remove = ['show', 'moreshow', 'less']\n",
        "\n",
        "    for d in df_col:\n",
        "        ## lowercase text\n",
        "        text = d.lower()\n",
        "        ## remove punctuation, keep it as string\n",
        "        text = \"\".join([c for c in text if c not in string.punctuation])\n",
        "        ## tokenization (definitely would use RegExp)\n",
        "        token_text = tokenizer.tokenize(text)\n",
        "        ## filter out stopwords\n",
        "        filt_tokens = [t for t in token_text if t not in stop_words]\n",
        "\n",
        "        ## get token stems or lemmas? (lemmas seems to have better results, according to below paper)\n",
        "        # stem_tokens = [stemmer.stem(t) for t in filt_tokens]\n",
        "        lemma_tokens = [lemmatizer.lemmatize(t) for t in filt_tokens]\n",
        "\n",
        "        ## removing \"show more/less\" idiosincracy \n",
        "        lemma_tokens = [i for i in lemma_tokens if i not in to_remove]\n",
        "\n",
        "        # ret_list.append(stem_tokens)\n",
        "        ret_list.append(lemma_tokens)\n",
        "\n",
        "    return ret_list\n",
        "\n",
        "# input: query string, return: lemmatized query string\n",
        "def standard_query(q):\n",
        "    \"\"\"\n",
        "    Similar to description, standardize the query input for appropriate results\n",
        "    :input: query string\n",
        "    :output: clean, standardized query string\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokenizer = RegexpTokenizer(pattern='\\w+|\\$[\\d\\.]+|\\S+') \n",
        "    # stemmer = PorterStemmer()\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # same preprocessing applied in \"process_description\", but for a given query\n",
        "    text = q.lower()\n",
        "    text = \"\".join([c for c in q if c not in string.punctuation])\n",
        "    token_text = tokenizer.tokenize(text)\n",
        "    filt_tokens = [t for t in token_text if t not in stop_words]\n",
        "\n",
        "    ## stemming or lemmatizing\n",
        "    # stemmed_query = [stemmer.stem(t) for t in filt_tokens]\n",
        "    lemmatized_query = [lemmatizer.lemmatize(t) for t in filt_tokens]\n",
        "\n",
        "    # query_str = \" \".join([c for c in stemmed_query])\n",
        "    query_str = \" \".join([c for c in lemmatized_query]).lower()\n",
        "\n",
        "    return query_str\n",
        "# standard_query(\"devops engineer\")\n",
        "\n",
        "\n",
        "# input: query string, return: bm25 scores list (can get top n scores)\n",
        "def query_scores(q):\n",
        "    \"\"\"\n",
        "    Function to get all the query scores given a query\n",
        "    :input: query\n",
        "    :output: document scores for a given query\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokenizer = RegexpTokenizer(pattern='\\w+|\\$[\\d\\.]+|\\S+')\n",
        "    # stemmer = PorterStemmer()\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # same preprocessing applied in \"process_description\"\n",
        "    text = q.lower()\n",
        "    text = \"\".join([c for c in text if c not in string.punctuation])\n",
        "    token_text = tokenizer.tokenize(text)\n",
        "    filt_tokens = [t for t in token_text if t not in stop_words]\n",
        "\n",
        "    # stemmed_query = [stemmer.stem(t) for t in filt_tokens]\n",
        "    lemmatized_query = [lemmatizer.lemmatize(t) for t in filt_tokens]\n",
        "\n",
        "    # get bm25 plus scores\n",
        "    # doc_scores = bm25.get_scores(stemmed_query)\n",
        "    doc_scores = bm25.get_scores(lemmatized_query)\n",
        "\n",
        "    # return sorted(doc_scores, reverse=True)[:10]\n",
        "    return doc_scores\n",
        "# query_scores(\"machine learning engineer\")\n",
        "\n",
        "\n",
        "# input: query string, corpus, top_n; return: df subset with entries from Full_DF, including naive relevance score\n",
        "def top_n_queries(query, corpus, n, column):\n",
        "    \"\"\"\n",
        "    Function to get top N queries, not only scores, but returning the dataframe with our relevant data\n",
        "    :input: query, corpus, top n\n",
        "    :output: df subset of entries from our complete df, with a naive relevance score\n",
        "    \"\"\"\n",
        "    query = standard_query(query)\n",
        "    tokenized_query = query.split(\" \")\n",
        "\n",
        "    top_n = bm25.get_top_n(query, corpus, n=n)\n",
        "    copy = df.copy()\n",
        "\n",
        "    # making clean_string column to return nice df of our results\n",
        "    ### adapted slightly, since now we're gonna find the matching title_and_description, no \"clean_string\" anymore\n",
        "    # copy[\"clean_string\"] = copy.description_clean.apply(lambda x: \" \".join([i for i in x]))\n",
        "\n",
        "    # creating simple relevance measure (ground truth) for the given query (if query in description, 1, else 0)\n",
        "    relevance = []\n",
        "\n",
        "    for cs in copy[column]:\n",
        "        if query in cs:\n",
        "            relevance.append(1)\n",
        "        else: \n",
        "            relevance.append(0)\n",
        "\n",
        "    copy[\"in_title\"] = relevance\n",
        "\n",
        "    return copy[copy[column].isin(top_n)]#.reset_index()\n",
        "    # return copy\n",
        "\n",
        "\n",
        "def retrieve_docs(query, **filters):\n",
        "    \"\"\"\n",
        "    Retrieve documents given a query, based on fitted BM25L (could vary algos) --- For this variation, \n",
        "    don't need to pick column to return (was for evaluation)\n",
        "    :input: query string, string of filters to exclude from results\n",
        "    :output: top 20 postings, alongside mAP evaluation score if set to True -- for final version, just return all postings? just 50\n",
        "    \"\"\"\n",
        "    qq = query\n",
        "\n",
        "    clean_filters = standard_query(str(list(filters.values())))\n",
        "    # print(clean_filters)\n",
        "\n",
        "    ## df with our results, will use to filter out stuff \n",
        "    given_query = top_n_queries(qq, corpus, len(df), \"company_title_entities\")\n",
        "    given_query[\"bm25_score\"] = query_scores(qq)\n",
        "\n",
        "    ## tokenize filter string to exclude from results \n",
        "    filter_tokens = word_tokenize(clean_filters)\n",
        "    # print(filter_tokens) \n",
        "\n",
        "    ## making a filter string, delimited by | as OR for multiple filters\n",
        "    masking_filter_string = ([\"|\".join(filter_tokens)])[0]\n",
        "\n",
        "    ## filtering our results based on the filter string entered by the user\n",
        "    ret_df = given_query[~given_query.company_title_entities.str.contains(masking_filter_string)]\n",
        "\n",
        "    ## now we have all columns available, so pick and choose to get a nice return df --> pick which !!!\n",
        "    ret_df = ret_df.sort_values(by=\"bm25_score\", ascending=False)[:50]#[['title','ds_rel','security_rel','ux_rel','bm25_score']]\n",
        "\n",
        "    return ret_df.reset_index(drop=True)\n",
        "\n",
        "def evaluate_mAP(retrieved_docs, rel_column):\n",
        "    \"\"\"\n",
        "    Function computes mean average precision (mAP) for the given query with ground truth annotations\n",
        "    :input: retrieved docs df, string of relevant column (either 'ds_rel', 'ux_rel', 'security_rel')\n",
        "    :output: mAP@20 score for given query\n",
        "    \"\"\"\n",
        "    # for security_docs\n",
        "    prec_list = []\n",
        "    relevant_count = 0\n",
        "\n",
        "    for i, b in enumerate(retrieved_docs[rel_column], 1):\n",
        "        if b > 0:\n",
        "            relevant_count += 1\n",
        "            prec_list.append(relevant_count/i)\n",
        "            # relevant_count += 1\n",
        "        if b <= 0:\n",
        "            prec_list.append(0/i)\n",
        "\n",
        "    mAP = sum(prec_list) / relevant_count\n",
        "\n",
        "    # print(prec_list)\n",
        "    # print(relevant_count)\n",
        "    return round(mAP, 6)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgxBAVx3V8Z0"
      },
      "source": [
        "## Data Preparation and Further Pre-Processing\n",
        "- Read in Full data (from our folder) to build our corpus\n",
        "- Creating different variations of df columns (detailed below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWlYmPhXT1QN"
      },
      "source": [
        "## need to read in FULL_DF to merge and get the description as well\n",
        "Full_DF = pd.read_csv(\"/content/drive/Shareddrives/SI650 Project [Info Retrieval]/data/FULL_DF.csv\")\n",
        "\n",
        "# description_clean was string of list of strings, use literal_eval to make it list of strings\n",
        "Full_DF.description_clean = Full_DF.description_clean.apply(lambda x: ast.literal_eval(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "93YnfN5yT1Nm",
        "outputId": "100ed039-5aec-4897-eb58-cdc659a8e52b"
      },
      "source": [
        "Full_DF.sample(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_id</th>\n",
              "      <th>link</th>\n",
              "      <th>apply_link</th>\n",
              "      <th>title</th>\n",
              "      <th>company</th>\n",
              "      <th>place</th>\n",
              "      <th>description</th>\n",
              "      <th>date</th>\n",
              "      <th>seniority</th>\n",
              "      <th>job_function</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>industries</th>\n",
              "      <th>description_clean</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6611</th>\n",
              "      <td>2220588268</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scien...</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/externalAp...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Virgin Galactic</td>\n",
              "      <td>Los Angeles, California, United States</td>\n",
              "      <td>Who We Are\\n\\nVirgin Galactic www.VirginGalac...</td>\n",
              "      <td>2020-10-23</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>Engineering, Information Technology</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Information Technology and Services, Aviation...</td>\n",
              "      <td>[virgin, galactic, wwwvirgingalacticcom, track...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          job_id  ... english\n",
              "6611  2220588268  ...       1\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcRjbRqxbz7F"
      },
      "source": [
        "## assignment of Full_DF to df for proper functioning with our helper functions. Now using full data!\n",
        "df = Full_DF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "E6ZXTB8uT1Fa",
        "outputId": "9cd35969-2137-4daa-9fdf-9baadb2295c6"
      },
      "source": [
        "df.sample(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_id</th>\n",
              "      <th>link</th>\n",
              "      <th>apply_link</th>\n",
              "      <th>title</th>\n",
              "      <th>company</th>\n",
              "      <th>place</th>\n",
              "      <th>description</th>\n",
              "      <th>date</th>\n",
              "      <th>seniority</th>\n",
              "      <th>job_function</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>industries</th>\n",
              "      <th>description_clean</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7021</th>\n",
              "      <td>2248381553</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/product-gr...</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/externalAp...</td>\n",
              "      <td>Product Growth Analyst</td>\n",
              "      <td>Facebook</td>\n",
              "      <td>New York, New York, United States</td>\n",
              "      <td>A prominent, data based global technology fir...</td>\n",
              "      <td>2020-10-27</td>\n",
              "      <td>Entry level</td>\n",
              "      <td>Engineering, Information Technology</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Information Technology and Services, Computer...</td>\n",
              "      <td>[prominent, data, based, global, technology, f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          job_id  ... english\n",
              "7021  2248381553  ...       1\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqi6TYkfT079",
        "outputId": "9e9b866f-02b6-4580-e76f-59727e937bbe"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12546, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd6TmCc8XR4u"
      },
      "source": [
        "### Adding Columns to our DataFrame\n",
        "- \"title_clean\" (list and string)\n",
        "- \"description_clean_string\"\n",
        "- \"title_and_description\"\n",
        "- \"entities\"\n",
        "- \"entities_list\"\n",
        "- \"entities_clean_string\"\n",
        "- \"title_and_entities\"\n",
        "- \"company_title_entities\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41YNdskKXUSJ"
      },
      "source": [
        "## didn't have clean title yet\n",
        "df[\"title_clean\"] = process_text(df.title)\n",
        "\n",
        "## make strings out of clean title and description to concatenate\n",
        "df[\"title_clean_string\"] = [\" \".join(i) for i in df.title_clean]\n",
        "df[\"description_clean_string\"] = [\" \".join(i) for i in df.description_clean]\n",
        "\n",
        "## create a new column with clean title + clean description for \"better\" retrieval, prolly use BM25L?\n",
        "df[\"title_and_description\"] = df.title_clean_string + \" \" + df.description_clean_string\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CX9Xmm7XCbU"
      },
      "source": [
        "## create an entities column, not clean yet but process the text after probably\n",
        "df[\"entities\"] = df[\"description\"].apply(lambda x: str((nlp(x).ents)).replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\"))\n",
        "\n",
        "## process_text returns a clean list of strings\n",
        "df[\"entities_list\"] = process_text(df.entities)\n",
        "\n",
        "## let's make the previous defined list into a clean string for concatenation with title\n",
        "df[\"entities_clean_string\"] = [\" \".join(i) for i in df.entities_list]\n",
        "\n",
        "## concatenating title and entities (similar to concatenating title and description)\n",
        "df[\"title_and_entities\"] = df.title_clean_string + \" \" + df.entities_clean_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk_4KCwk34C9"
      },
      "source": [
        "## creating token list for company, and a clean string of company name for concatenation\n",
        "df[\"company_token_list\"] = process_text(df.company)\n",
        "df[\"company_clean_string\"] = [\" \".join(i) for i in df.company_token_list]\n",
        "\n",
        "## concatenate company name, job title, and extracted entities\n",
        "df[\"company_title_entities\"] = df.company_clean_string + \" \" + df.title_clean_string + \" \" + df.entities_clean_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "Lz0oahuqhYnz",
        "outputId": "228220a7-5b84-46f3-8c9d-44ba64efe63c"
      },
      "source": [
        "df.sample(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_id</th>\n",
              "      <th>link</th>\n",
              "      <th>apply_link</th>\n",
              "      <th>title</th>\n",
              "      <th>company</th>\n",
              "      <th>place</th>\n",
              "      <th>description</th>\n",
              "      <th>date</th>\n",
              "      <th>seniority</th>\n",
              "      <th>job_function</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>industries</th>\n",
              "      <th>description_clean</th>\n",
              "      <th>english</th>\n",
              "      <th>title_clean</th>\n",
              "      <th>title_clean_string</th>\n",
              "      <th>description_clean_string</th>\n",
              "      <th>title_and_description</th>\n",
              "      <th>entities</th>\n",
              "      <th>entities_list</th>\n",
              "      <th>entities_clean_string</th>\n",
              "      <th>title_and_entities</th>\n",
              "      <th>company_token_list</th>\n",
              "      <th>company_clean_string</th>\n",
              "      <th>company_title_entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8289</th>\n",
              "      <td>2251347305</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/c%23-dw-fu...</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/externalAp...</td>\n",
              "      <td>C# DW Full Stack Developer</td>\n",
              "      <td>CareerAddict</td>\n",
              "      <td>Chicago, IL</td>\n",
              "      <td>\\nC# Full Stack Developer\\n\\n*We are unable t...</td>\n",
              "      <td>2020-10-29</td>\n",
              "      <td>Entry level</td>\n",
              "      <td>Engineering, Information Technology</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Computer &amp; Network Security\\n</td>\n",
              "      <td>[c, full, stack, developer, unable, sponsor, p...</td>\n",
              "      <td>1</td>\n",
              "      <td>[c, dw, full, stack, developer]</td>\n",
              "      <td>c dw full stack developer</td>\n",
              "      <td>c full stack developer unable sponsor permanen...</td>\n",
              "      <td>c dw full stack developer c full stack develop...</td>\n",
              "      <td>C# unable to sponsor API Report development SS...</td>\n",
              "      <td>[c, unable, sponsor, api, report, development,...</td>\n",
              "      <td>c unable sponsor api report development ssrs d...</td>\n",
              "      <td>c dw full stack developer c unable sponsor api...</td>\n",
              "      <td>[careeraddict]</td>\n",
              "      <td>careeraddict</td>\n",
              "      <td>careeraddict c dw full stack developer c unabl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          job_id  ...                             company_title_entities\n",
              "8289  2251347305  ...  careeraddict c dw full stack developer c unabl...\n",
              "\n",
              "[1 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLtzbP8bi3m2"
      },
      "source": [
        "## BM25 Model Retrieval\n",
        "- For our final model, we use BM25L and the \"company_title_entities\" column as the corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "2t1HDNnAjx9K",
        "outputId": "3509d316-033a-4aac-e602-77ed021989bc"
      },
      "source": [
        "df.sample(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_id</th>\n",
              "      <th>link</th>\n",
              "      <th>apply_link</th>\n",
              "      <th>title</th>\n",
              "      <th>company</th>\n",
              "      <th>place</th>\n",
              "      <th>description</th>\n",
              "      <th>date</th>\n",
              "      <th>seniority</th>\n",
              "      <th>job_function</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>industries</th>\n",
              "      <th>description_clean</th>\n",
              "      <th>english</th>\n",
              "      <th>title_clean</th>\n",
              "      <th>title_clean_string</th>\n",
              "      <th>description_clean_string</th>\n",
              "      <th>title_and_description</th>\n",
              "      <th>entities</th>\n",
              "      <th>entities_list</th>\n",
              "      <th>entities_clean_string</th>\n",
              "      <th>title_and_entities</th>\n",
              "      <th>company_token_list</th>\n",
              "      <th>company_clean_string</th>\n",
              "      <th>company_title_entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10153</th>\n",
              "      <td>2243755423</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/automotive...</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/externalAp...</td>\n",
              "      <td>Automotive Systems Engineer</td>\n",
              "      <td>ESG Automotive USA</td>\n",
              "      <td>Detroit, Michigan, United States</td>\n",
              "      <td>Mission of the Position:\\n\\n\\n\\n\\n\\nThe Syste...</td>\n",
              "      <td>2020-10-01</td>\n",
              "      <td>Mid-Senior level</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Automotive\\n</td>\n",
              "      <td>[mission, position, system, engineer, advanced...</td>\n",
              "      <td>1</td>\n",
              "      <td>[automotive, system, engineer]</td>\n",
              "      <td>automotive system engineer</td>\n",
              "      <td>mission position system engineer advanced engi...</td>\n",
              "      <td>automotive system engineer mission position sy...</td>\n",
              "      <td>Mission leading- team IP Magna's Health Health...</td>\n",
              "      <td>[mission, leading, team, ip, magnas, health, h...</td>\n",
              "      <td>mission leading team ip magnas health health f...</td>\n",
              "      <td>automotive system engineer mission leading tea...</td>\n",
              "      <td>[esg, automotive, usa]</td>\n",
              "      <td>esg automotive usa</td>\n",
              "      <td>esg automotive usa automotive system engineer ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           job_id  ...                             company_title_entities\n",
              "10153  2243755423  ...  esg automotive usa automotive system engineer ...\n",
              "\n",
              "[1 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f__Xvgglmt10",
        "outputId": "3f2c25f2-9ac0-4db6-d558-84cb81838a6c"
      },
      "source": [
        "### CHANGE THE BM25 VARIANT AND THE DIFFERENT COLUMNS TO BE FIT INTO BM25 -- Final model uses company+title+entities with BM25L\n",
        "\n",
        "## define corpus from our target data (input should be the string version of the column)\n",
        "corpus = []\n",
        "\n",
        "## hardcoding \"company_title_entities\" to use as corpus for indexing\n",
        "for i in df[\"company_title_entities\"].values:\n",
        "    corpus.append(i)\n",
        "\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "\n",
        "## implement BM25 algo for retrieval\n",
        "## https://github.com/dorianbrown/rank_bm25/blob/master/rank_bm25.py\n",
        "\n",
        "bm25 = BM25L(tokenized_corpus) #k1=1.5, b=0.75, delta=0.5\n",
        "bm25"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rank_bm25.BM25L at 0x7f72fd26c5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt6bVeoZFTKi"
      },
      "source": [
        "## Retrieve Documents\n",
        "- input: query string, [optional] filters string\n",
        "- output: top 50 job postings according to our retrieval model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXwavFROv-c0"
      },
      "source": [
        "## the column variable, make sure it matches with the column that was fitted into BM25 model\n",
        "\n",
        "## to test out the retrieval model, change the query and filters to whatever.\n",
        "## QUERY: a string with a job title, maybe some skills\n",
        "## FILTERS: a string with a few keywords you want to exclude from your search results\n",
        "\n",
        "query = \"developer engineer sql python\"\n",
        "filters = \"jp morgan security\"\n",
        "\n",
        "retrieved_documents = retrieve_docs(query=query, filters=filters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VECVEIGj5FlI",
        "outputId": "7f5b0966-b0af-4f8d-fdcd-5a085f85bd66"
      },
      "source": [
        "## start picking nice output for person looking for the job (should we include description? Not very \"clean\", better to just give a link?)\n",
        "## returning top 5 documents\n",
        "\n",
        "cols_return = [\"title\", \"company\", \"seniority\", \"job_function\", \"employment_type\", \"link\"]#, \"bm25_score\"]\n",
        "retrieved_documents[cols_return][:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>company</th>\n",
              "      <th>seniority</th>\n",
              "      <th>job_function</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SQL Developer</td>\n",
              "      <td>EdgeLink</td>\n",
              "      <td>Mid-Senior level</td>\n",
              "      <td>Information Technology</td>\n",
              "      <td>Contract</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/sql-develo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Python / Django Developer</td>\n",
              "      <td>OneinaMil, LLC</td>\n",
              "      <td>Entry level</td>\n",
              "      <td>Engineering, Information Technology</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/python-dja...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Financial Analyst II</td>\n",
              "      <td>Adventist HealthCare</td>\n",
              "      <td>Mid-Senior level</td>\n",
              "      <td>Information Technology</td>\n",
              "      <td>Contract</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/financial-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Analyst, Finance</td>\n",
              "      <td>Faire</td>\n",
              "      <td>Associate</td>\n",
              "      <td>Business Development, Sales</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-analy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Operations Analyst, Inspection Center Team</td>\n",
              "      <td>Carvana</td>\n",
              "      <td>Associate</td>\n",
              "      <td>Business Development, Sales</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/operations...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          title  ...                                               link\n",
              "0                                SQL Developer   ...   https://www.linkedin.com/jobs/view/sql-develo...\n",
              "1                    Python / Django Developer   ...   https://www.linkedin.com/jobs/view/python-dja...\n",
              "2                         Financial Analyst II   ...   https://www.linkedin.com/jobs/view/financial-...\n",
              "3                        Data Analyst, Finance   ...   https://www.linkedin.com/jobs/view/data-analy...\n",
              "4   Operations Analyst, Inspection Center Team   ...   https://www.linkedin.com/jobs/view/operations...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpilM5P_w4qB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dzX6fuTwWHk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}